Please update python_scripts/train_meridian_corrected.py to fix the control coefficient and saturation parameter extraction. Replace lines 434-511 with this exact code:

# Extract control variable analysis using private methods
control_analysis = {}
if config.get('control_columns') and len(config['control_columns']) > 0:
    try:
        control_names = [col for col in config['control_columns'] if col != 'population']
        
        # Check model's _inference_data for posterior samples
        if hasattr(model, '_inference_data'):
            inf_data = model._inference_data
            if hasattr(inf_data, 'posterior'):
                posterior = inf_data.posterior
                print(json.dumps({"posterior_vars": list(posterior.data_vars)[:20]}))
                
                # Look for control coefficients
                for i, control_name in enumerate(control_names):
                    # Try different naming conventions
                    possible_vars = [
                        f'beta_control[{i}]',
                        f'beta_controls[{i}]',
                        f'control[{i}]',
                        f'controls[{i}]',
                        f'beta_{control_name}'
                    ]
                    
                    for var_name in possible_vars:
                        if var_name in posterior.data_vars:
                            data = posterior[var_name]
                            values = data.values.flatten()
                            
                            control_analysis[control_name] = {
                                "coefficient": float(np.mean(values)),
                                "std_error": float(np.std(values)),
                                "ci_lower": float(np.percentile(values, 2.5)),
                                "ci_upper": float(np.percentile(values, 97.5)),
                                "p_value": 0.01 if (np.percentile(values, 2.5) > 0 or np.percentile(values, 97.5) < 0) else 0.10,
                                "impact": "positive" if np.mean(values) > 0 else "negative",
                                "significance": "significant" if (np.percentile(values, 2.5) > 0 or np.percentile(values, 97.5) < 0) else "not significant"
                            }
                            print(json.dumps({"found_control": control_name, "var": var_name}))
                            break
                            
    except Exception as e:
        print(json.dumps({"control_extraction_error": str(e)}))

# Extract saturation parameters using private methods
try:
    # Use the private hill curves method
    if hasattr(model_analyzer, '_get_hill_curves_dataframe'):
        hill_df = model_analyzer._get_hill_curves_dataframe()
        print(json.dumps({
            "hill_df_shape": str(hill_df.shape),
            "hill_df_columns": list(hill_df.columns) if hasattr(hill_df, 'columns') else []
        }))
        
        # Check what's in the first few rows
        if hasattr(hill_df, 'head'):
            print(json.dumps({
                "hill_df_sample": hill_df.head(2).to_dict()
            }))
        
        # Process the dataframe to extract EC and slope per channel
        for i, channel in enumerate(channels):
            try:
                # Filter for this channel - try different column names
                channel_data = None
                if 'channel' in hill_df.columns:
                    channel_data = hill_df[hill_df['channel'] == channel]
                elif 'media_channel' in hill_df.columns:
                    channel_data = hill_df[hill_df['media_channel'] == channel]
                elif 'media' in hill_df.columns:
                    channel_data = hill_df[hill_df['media'] == channel]
                
                if channel_data is not None and len(channel_data) > 0:
                    # Look for EC and slope with various possible names
                    ec_columns = ['ec', 'half_max_effective_concentration', 'half_saturation', 'EC']
                    slope_columns = ['slope', 'hill_slope', 'shape', 'beta']
                    
                    for ec_col in ec_columns:
                        if ec_col in channel_data.columns:
                            response_curves[channel]["saturation"]["ec"] = float(channel_data[ec_col].mean())
                            print(json.dumps({"found_ec": channel, "column": ec_col}))
                            break
                    
                    for slope_col in slope_columns:
                        if slope_col in channel_data.columns:
                            response_curves[channel]["saturation"]["slope"] = float(channel_data[slope_col].mean())
                            print(json.dumps({"found_slope": channel, "column": slope_col}))
                            break
                            
            except Exception as e:
                print(json.dumps({"hill_channel_error": channel, "error": str(e)}))
    
    # Alternative: Check model's _inference_data for Hill parameters
    if hasattr(model, '_inference_data'):
        inf_data = model._inference_data
        if hasattr(inf_data, 'posterior'):
            posterior = inf_data.posterior
            
            # Look for Hill parameters with various naming conventions
            for i, channel in enumerate(channels):
                # Try different variable names
                ec_vars = [f'ec[{i}]', f'hill_ec[{i}]', f'half_max_effective_concentration[{i}]', f'ec_{i}']
                slope_vars = [f'slope[{i}]', f'hill_slope[{i}]', f'beta[{i}]', f'slope_{i}']
                
                for ec_var in ec_vars:
                    if ec_var in posterior.data_vars:
                        ec_values = posterior[ec_var].values.flatten()
                        response_curves[channel]["saturation"]["ec"] = float(np.mean(ec_values))
                        print(json.dumps({"found_posterior_ec": channel, "var": ec_var}))
                        break
                
                for slope_var in slope_vars:
                    if slope_var in posterior.data_vars:
                        slope_values = posterior[slope_var].values.flatten()
                        response_curves[channel]["saturation"]["slope"] = float(np.mean(slope_values))
                        print(json.dumps({"found_posterior_slope": channel, "var": slope_var}))
                        break
                        
except Exception as e:
    print(json.dumps({"saturation_extraction_error": str(e)}))

Show me the updated code when complete.